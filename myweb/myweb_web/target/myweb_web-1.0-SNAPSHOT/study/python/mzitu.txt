import urllib.request
import os
import time
import sys
import csv


def open_url(url) -> 'html':
    """接受一个URL，使用代理IP, 返回二进制页面"""

    # http://ip.zdaye.com/dayProxy.html 可以在该网站获得临时代理ip，注意是http协议还是https
    proxy_support = urllib.request.ProxyHandler({'http': '58.244.193.68:8080'})
    opener = urllib.request.build_opener(proxy_support)
    """设置请求头信息"""
    opener.addheaders = [('User-Agent',
                          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/17.17134')]
    urllib.request.install_opener(opener)

    """req = urllib.request.request(url)"""
    """#req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/17.17134')"""
    try:
        response = urllib.request.urlopen(url)
    except Exception as err:
        print('地址打开失败:', str(err))
    # 读取响应结果
    html = response.read()

    return html


def get_page(url) -> int:
    """获得最新页码，返回值为整型"""

    # 获取页面并解码
    html_decode = open_url(url).decode('utf-8')
    # 查找起始位置
    index_start = html_decode.find('page-numbers current')
    # 在index_start位置向后50查找
    index_end = html_decode.find('span', index_start, index_start + 50)
    if index_end != -1:
        # 如果找到则获取页码
        num = html_decode[index_start + 22: index_end - 2]
    else:
        print('Not find index_end')

    return int(num)


def get_img_url(url) -> list:
    """获得当前页面所有图片地址，返回列表"""

    # 定义列表
    img_address = []
    # 获取页面内容
    time.sleep(5)
    html_decode = open_url(url).decode('utf-8')

    index_start = html_decode.find('data-original=')
    # index = 1
    while index_start != -1:
        index_end = html_decode.find('.jpg', index_start, index_start + 99)

        if index_end != -1:
            # print(str(index) + ': ' + html_decode[index_start+15: index_end+4])
            img_address.append(html_decode[index_start + 15: index_end + 4])
        else:
            index_end = index_start + 99
            print('Not find index_end in get_img_url')

        # index = index + 1
        # 查询下一张图片 从上一次的结束位置开始查
        index_start = html_decode.find('data-original=', index_end)

    return img_address


def img_url_save(img_dict) -> None:
    """保存图片地址"""
    # 保存到csv文件有问题，会重复存储
    img_name_list = []

    with open('img_url.csv', 'a+') as f:
        ignore = f.readline()
        if ignore is not None:
            for line in f:
                k, v = line.strip().split(',')
                img_name_list.append(k)

    for k, v in img_dict.items():
        with open('img_url.csv', 'a', newline='') as f:
            filename = ['img_name', 'img_url']
            writer = csv.DictWriter(f, fieldnames=filename)
            if k not in img_name_list:
                writer.writerow({'img_name': k, 'img_url': v})


def img_save(img_list: list) -> None:
    """保存图片"""
    # 定义列表
    img_dict = {}

    for each in img_list:
        img_name = each.split('/')[-1]
        img_dict[img_name] = each

        with open(img_name, 'wb') as f:
            f.write(open_url(each))
            # 模拟实际，时间间隔2秒
            time.sleep(2)

    # 有问题img_url_save(img_dict)


def main_start() -> int:
    """读取上次下载到的页面，返回整形，"""

    try:
        with open('num.txt') as f:
            num = int(f.read())
            print('上次更新到第%d页！' % num)
    except:
        print('文件打开失败，如果这是第一次使用请忽略')
        num = None

    return num


def choice() -> None:
    """询问用户是否选择更新"""

    request = input('请选择是否更新(Y/N): ')

    while request != 'Y' and request != 'N' and request != 'y' and request != 'n':
        request = input('请输入字符(y/n): ')

    if request == 'N' or request == 'n':
        print('正在结束...')
        sys.exit(0)


def main() -> None:
    """改变numb值，来获得最新多少页的图片"""

    # 获取当前目录
    path = os.getcwd()
    print('当前目录：' + path)
    # 要爬取的网页地址
    url = 'http://www.mzitu.com/zipai/'
    # 读取上次爬到的页面位置
    page_ago = main_start()
    while page_ago is None:
        try:
            page_ago = 387
            os.mkdir('Mzi_down')
        except Exception as err:
            print('文件夹已经存在')
            break

    # 最新页码
    print('正在获取页码……')
    page_now = get_page(url)
    print('网站更新到第%d页！' % page_now)

    # 判断是否更新
    if page_ago is not None:
        choice()

    # 改变工作目录
    os.chdir('Mzi_down')
    print('当前目录：' + os.getcwd())

    numb = page_now - page_ago

    if numb == 0:
        print('没有可用更新！\n正在结束...')
        sys.exit(0)

    # 循环获得每页的数据
    for i in range(numb):
        # 字符串拼接获取完整页面url
        new_url = url + 'comment-page-' + str(page_ago + i)
        print('当前页面地址' + new_url)
        print('正在获取图片地址...')
        img_list = get_img_url(new_url)
        print('图片地址获取成功！')
        print('正在下载图片...')
        img_save(img_list)
        print('图片下载成功！')

    # 记录最新页码
    os.chdir(path)
    with open('num.txt', 'w') as f:
        f.write(str(page_now))
    sys.exit(0)


if __name__ == '__main__':
    main()
